import os
from datetime import datetime, timedelta
from airflow import DAG
from airflow.providers.apache.spark.operators.spark_submit import SparkSubmitOperator

# Ð‘Ð°Ð·Ð¾Ð²Ñ– Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð¸ DAG
default_args = {
    'owner': 'zyaremko',
    'depends_on_past': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

# ÐŸÐ¾Ñ‚Ð¾Ñ‡Ð½Ð° Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ñ–Ñ (Ñ‰Ð¾Ð± Ð¿Ñ€Ð°Ñ†ÑŽÐ²Ð°Ð»Ð¸ Ð²Ñ–Ð´Ð½Ð¾ÑÐ½Ñ– ÑˆÐ»ÑÑ…Ð¸)
current_directory = os.path.dirname(os.path.abspath(__file__))

with DAG(
    dag_id='zyaremko_final_part2_pipeline',   # ðŸ‘ˆ Ñ‚Ð²Ñ–Ð¹ ÑƒÐ½Ñ–ÐºÐ°Ð»ÑŒÐ½Ð¸Ð¹ DAG ID
    default_args=default_args,
    description='Landing -> Bronze -> Silver -> Gold Spark jobs (Part 2)',
    schedule_interval=None,                   # Ñ€ÑƒÑ‡Ð½Ð¸Ð¹ Ð·Ð°Ð¿ÑƒÑÐº
    start_date=datetime(2025, 9, 22),         # Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ð° Ð´Ð°Ñ‚Ð° ÑÑ‚Ð°Ñ€Ñ‚Ñƒ
    catchup=False,
    max_active_runs=1,
    tags=["zyaremko", "final_project"]        # ðŸ‘ˆ Ñ‰Ð¾Ð± Ð»ÐµÐ³ÐºÐ¾ Ð·Ð½Ð°Ð¹Ñ‚Ð¸ Ñƒ Airflow
) as dag:

    # Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ 1: Landing -> Bronze
    landing_to_bronze = SparkSubmitOperator(
        application=os.path.join(current_directory, 'landing_to_bronze.py'),
        task_id='landing_to_bronze',
        conn_id='spark-default',
        verbose=1
    )

    # Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ 2: Bronze -> Silver
    bronze_to_silver = SparkSubmitOperator(
        application=os.path.join(current_directory, 'bronze_to_silver.py'),
        task_id='bronze_to_silver',
        conn_id='spark-default',
        verbose=1
    )

    # Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ 3: Silver -> Gold
    silver_to_gold = SparkSubmitOperator(
        application=os.path.join(current_directory, 'silver_to_gold.py'),
        task_id='silver_to_gold',
        conn_id='spark-default',
        verbose=1
    )

    # Ð’ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð½Ñ Ð¿Ð¾ÑÐ»Ñ–Ð´Ð¾Ð²Ð½Ð¾ÑÑ‚Ñ–
    landing_to_bronze >> bronze_to_silver >> silver_to_gold

